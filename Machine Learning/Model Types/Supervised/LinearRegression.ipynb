{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning outcomes\n",
    "\n",
    "* Understanding the loss function for linear regression\n",
    "* Understanding the solution to least squares through the normal equation\n",
    "* Understanding the solution to least squares through the gradient descent\n",
    "* Understanding the how $R^2$ is defined and its significance\n",
    "* Understanding the RMSE loss\n",
    "* Understanding the MAE\n",
    "* Understanding the LRMSE\n",
    "* Implementing linear regression in sklearn\n",
    "* Implementing linear regression in statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://www.youtube.com/embed/CtKeHnfK5uA\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10b4ae850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://www.youtube.com/embed/CtKeHnfK5uA',560,315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "The estimator is $h_{\\theta} = \\theta_0x_0+\\theta_1x_1+\\theta_2x_2+...++\\theta_nx_n$\n",
    "\n",
    "The cost function(the function we want to optimize) is \n",
    "$\\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x) - y)$\n",
    "\n",
    "In matrix form the equation becomes $X\\theta = y$\n",
    "\n",
    "Where X is an observation(m) by feature matrix(n)\n",
    "\n",
    "$\\theta$ is a n+1 column vector and \n",
    "\n",
    "y is a size m column vector.\n",
    "\n",
    "We want to solve for the set of weights ($\\theta$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Equation\n",
    "\n",
    "The analytical solution to the above formulation is known as the normal equation.\n",
    "\n",
    "Assuming $X^TX$ exists, $\\theta = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "This formulation of linear regression can be found in numpy.linalg package under the name \"lstsq\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The m becomes large especially for m > 10^4, the above equation becomes difficult to solve.\n",
    "\n",
    "An alternate formulation involves iteratively changing the weight vector $\\theta$ with respect to the cost function. This approach is used most frequently with deep learning methods.\n",
    "\n",
    "You can find a brief explanation of gradient descent [here.](https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient of Determination (R^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Sometimes, it is helpful to think about how well the model is doing then just predicting the mean.</p>\n",
    "<p>For the general use case, we will use this explain how much of the variance in the dependent variable is captured by the independent variables.</p>\n",
    "<p> * The equations * </p>\n",
    "$SS_{total} = \\sum(y_{i} - \\bar{y})^2$  , $SS_{residual} = \\sum(y_{i} - \\hat{y})$\n",
    "where $y_{i}$ is the dependent variable, $\\hat{y}$ is the prediction and $\\bar{y}$ is the mean of $y$.\n",
    "\n",
    "<p> We define $R^2 = 1 - \\frac{SS_{residual}}{SS_{total}}$ </p>\n",
    "\n",
    "$R^2$ close to one means the model performs better than the horizontal line while an $R^2$ of zero means the model performs worse than the horizontal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(tips.total_bill.values.reshape(-1, 1),tips.tip.values)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared is 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(X_test,y_test)\n",
    "plt.plot(X_test,predictions)\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R-squared is\",r2_score(y_test,predictions).round(2))\n",
    "\n",
    "# As you can see a low r^2 corresponds to a poor explanation of the variation of the underlying system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{RMSE} = \\sqrt{\\sum_{i=1}^{N}\\frac{(\\hat{y_i} - y_i)^2}{N}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is it good for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is in the same scale as the dependent variable.\n",
    "- It places higher weight on bigger errors. This means if you make a far off prediction, the error^2 will be very high.\n",
    "- For that reason it is not robust to outliers.\n",
    "- It's advisible to you this metric when outliers are in fact outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{MAE} = \\sum_{i=1}^{N}\\frac{|\\hat{y_i} - y_i|}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is it good for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is in the same scale as the dependent variable.\n",
    "- Unlike RMSE it does not place high weight on far off predictions.\n",
    "- For this reason it is more robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Root Mean Squared Error (LRMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially RMSE when the dependent variable is transformed to log space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is it good for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you don't care about the exact prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = load_boston(return_X_y=False)['feature_names']\n",
    "X,y = load_boston(return_X_y=True)\n",
    "df = pd.DataFrame(X,columns=features)\n",
    "df[\"target\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared is 0.635\n",
      "Root mean squared error is 5.457\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "preds = lr.predict(X_test)\n",
    "print(\"R-squared is\",r2_score(y_test,preds).round(3))\n",
    "print(\"Root mean squared error is\",np.sqrt(mean_squared_error(y_test,preds)).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients are [-1.17735289e-01  4.40174969e-02 -5.76814314e-03  2.39341594e+00\n",
      " -1.55894211e+01  3.76896770e+00 -7.03517828e-03 -1.43495641e+00\n",
      "  2.40081086e-01 -1.12972810e-02 -9.85546732e-01  8.44443453e-03\n",
      " -4.99116797e-01]\n",
      "Intercept is 36.933255457118975\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients are\",lr.coef_)\n",
    "print(\"Intercept is\",lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/envs/QMIND2/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11631155,  0.04582511, -0.03406271,  2.54347348, -0.07737062,\n",
       "        5.97510447, -0.01528812, -0.92550879,  0.1045704 , -0.00864844,\n",
       "       -0.4486441 ,  0.01412772, -0.38141142])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y_train,X_train)\n",
    "results = model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.963</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.962</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   738.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 22 Jun 2020</td> <th>  Prob (F-statistic):</th>          <td>2.27e-253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:35:25</td>     <th>  Log-Likelihood:    </th>          <td> -1122.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   379</td>      <th>  AIC:               </th>          <td>   2272.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   366</td>      <th>  BIC:               </th>          <td>   2323.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>   -0.1163</td> <td>    0.040</td> <td>   -2.944</td> <td> 0.003</td> <td>   -0.194</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>    0.0458</td> <td>    0.016</td> <td>    2.895</td> <td> 0.004</td> <td>    0.015</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>   -0.0341</td> <td>    0.070</td> <td>   -0.485</td> <td> 0.628</td> <td>   -0.172</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>    2.5435</td> <td>    1.014</td> <td>    2.508</td> <td> 0.013</td> <td>    0.549</td> <td>    4.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>   -0.0774</td> <td>    3.812</td> <td>   -0.020</td> <td> 0.984</td> <td>   -7.573</td> <td>    7.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>    5.9751</td> <td>    0.346</td> <td>   17.252</td> <td> 0.000</td> <td>    5.294</td> <td>    6.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>   -0.0153</td> <td>    0.016</td> <td>   -0.975</td> <td> 0.330</td> <td>   -0.046</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>   -0.9255</td> <td>    0.222</td> <td>   -4.178</td> <td> 0.000</td> <td>   -1.361</td> <td>   -0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    0.1046</td> <td>    0.074</td> <td>    1.423</td> <td> 0.156</td> <td>   -0.040</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>   -0.0086</td> <td>    0.004</td> <td>   -2.027</td> <td> 0.043</td> <td>   -0.017</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>   -0.4486</td> <td>    0.126</td> <td>   -3.566</td> <td> 0.000</td> <td>   -0.696</td> <td>   -0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>    0.0141</td> <td>    0.003</td> <td>    4.608</td> <td> 0.000</td> <td>    0.008</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>   -0.3814</td> <td>    0.058</td> <td>   -6.615</td> <td> 0.000</td> <td>   -0.495</td> <td>   -0.268</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>179.629</td> <th>  Durbin-Watson:     </th> <td>   2.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1538.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.798</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>12.194</td>  <th>  Cond. No.          </th> <td>8.70e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.7e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.963\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.962\n",
       "Method:                 Least Squares   F-statistic:                              738.2\n",
       "Date:                Mon, 22 Jun 2020   Prob (F-statistic):                   2.27e-253\n",
       "Time:                        18:35:25   Log-Likelihood:                         -1122.8\n",
       "No. Observations:                 379   AIC:                                      2272.\n",
       "Df Residuals:                     366   BIC:                                      2323.\n",
       "Df Model:                          13                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.1163      0.040     -2.944      0.003      -0.194      -0.039\n",
       "x2             0.0458      0.016      2.895      0.004       0.015       0.077\n",
       "x3            -0.0341      0.070     -0.485      0.628      -0.172       0.104\n",
       "x4             2.5435      1.014      2.508      0.013       0.549       4.538\n",
       "x5            -0.0774      3.812     -0.020      0.984      -7.573       7.419\n",
       "x6             5.9751      0.346     17.252      0.000       5.294       6.656\n",
       "x7            -0.0153      0.016     -0.975      0.330      -0.046       0.016\n",
       "x8            -0.9255      0.222     -4.178      0.000      -1.361      -0.490\n",
       "x9             0.1046      0.074      1.423      0.156      -0.040       0.249\n",
       "x10           -0.0086      0.004     -2.027      0.043      -0.017      -0.000\n",
       "x11           -0.4486      0.126     -3.566      0.000      -0.696      -0.201\n",
       "x12            0.0141      0.003      4.608      0.000       0.008       0.020\n",
       "x13           -0.3814      0.058     -6.615      0.000      -0.495      -0.268\n",
       "==============================================================================\n",
       "Omnibus:                      179.629   Durbin-Watson:                   2.029\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1538.969\n",
       "Skew:                           1.798   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.194   Cond. No.                     8.70e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.7e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared is 0.599\n",
      "Root mean squared error is 5.722\n"
     ]
    }
   ],
   "source": [
    "preds = results.predict(X_test)\n",
    "print(\"R-squared is\",r2_score(y_test,preds).round(3))\n",
    "print(\"Root mean squared error is\",np.sqrt(mean_squared_error(y_test,preds)).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "https://www.coursera.org/learn/machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
